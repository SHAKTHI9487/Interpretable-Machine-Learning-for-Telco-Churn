{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70565c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:23: SyntaxWarning: invalid escape sequence '\\H'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\H'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_23420\\2189942425.py:23: SyntaxWarning: invalid escape sequence '\\H'\n",
      "  DATA_PATH = \"C:\\\\Users\\Hp\\OneDrive\\Desktop\\WA_Fn-UseC_-Telco-Customer-Churn.csv\"  # change if needed\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_23420\\2189942425.py:24: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  OUTPUT_FOLDER = \"D:\\Cultus\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: C:\\Users\\Hp\\OneDrive\\Desktop\\WA_Fn-UseC_-Telco-Customer-Churn.csv\n",
      "Shape: (7043, 21)\n",
      "Column tenure convertible fraction: 1.000\n",
      "Column MonthlyCharges convertible fraction: 1.000\n",
      "Column TotalCharges convertible fraction: 0.998\n",
      "Train/test shapes: (5282, 30) (1761, 30)\n",
      "XGBoost available\n",
      "Set booster.base_score to numeric string '0.5' to avoid SHAP parsing issues\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Cultus\\Capstone_Project\\venv\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [11:26:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics -> AUC: 0.8190, Precision: 0.5565, Recall: 0.6745, F1: 0.6099\n",
      "SHAP version: 0.49.1\n",
      "TreeExplainer failed: ValueError could not convert string to float: '[5E-1]'\n",
      "Trying shap.Explainer with model.predict_proba and numpy arrays (slower)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 1762it [00:52, 31.63it/s]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shap.Explainer succeeded\n",
      "Top 10 features by mean |SHAP|:\n",
      "tenure                            0.085159\n",
      "Contract_Two year                 0.074975\n",
      "MonthlyCharges                    0.064387\n",
      "TotalCharges                      0.055544\n",
      "Contract_One year                 0.042557\n",
      "InternetService_Fiber optic       0.042256\n",
      "OnlineSecurity_Yes                0.026766\n",
      "PaperlessBilling_Yes              0.025877\n",
      "InternetService_No                0.023427\n",
      "PaymentMethod_Electronic check    0.022971\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_23420\\2189942425.py:216: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values_pos, X_test_np, show=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected indices for local SHAP: {'predicted_churn': 2516, 'predicted_nonchurn': 5909, 'borderline': 717}\n",
      "SHAP artifacts saved to: D:\\Cultus\n",
      "Done. Outputs in: D:\\Cultus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# telco_churn_shap_final\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
    "\n",
    "# --------------- CONFIG ---------------\n",
    "DATA_PATH = \"C:\\\\Users\\Hp\\OneDrive\\Desktop\\WA_Fn-UseC_-Telco-Customer-Churn.csv\"  # change if needed\n",
    "OUTPUT_FOLDER = \"D:\\Cultus\"\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# --------------- helpers ---------------\n",
    "def clean_numeric_string(val):\n",
    "    \"\"\"\n",
    "    Clean numeric-like strings: remove brackets, parentheses, currency, commas and common NA tokens.\n",
    "    \"\"\"\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    if not isinstance(val, str):\n",
    "        return val\n",
    "    s = val.strip()\n",
    "    if s == \"\":\n",
    "        return np.nan\n",
    "    # Remove surrounding brackets or parentheses\n",
    "    if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
    "        s = s[1:-1].strip()\n",
    "    # Remove punctuation often present in numbers\n",
    "    for ch in [\",\", \"$\", \"â‚¹\", \"%\", '\"', \"'\"]:\n",
    "        s = s.replace(ch, \"\")\n",
    "    if s.lower() in (\"na\", \"n/a\", \"none\", \"nan\", \"null\", \"unknown\", \"\"):\n",
    "        return np.nan\n",
    "    return s\n",
    "\n",
    "def robust_convert_numeric(series):\n",
    "    cleaned = series.astype(object).map(clean_numeric_string)\n",
    "    coerced = pd.to_numeric(cleaned, errors='coerce')\n",
    "    success_frac = coerced.notna().sum() / len(coerced)\n",
    "    return coerced, success_frac\n",
    "\n",
    "# --------------- 1. Load ---------------\n",
    "print(\"Loading data:\", DATA_PATH)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# --------------- 2. Clean numeric columns ---------------\n",
    "numeric_candidates = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "for col in numeric_candidates:\n",
    "    if col in df.columns:\n",
    "        coerced, frac = robust_convert_numeric(df[col])\n",
    "        print(f\"Column {col} convertible fraction: {frac:.3f}\")\n",
    "        df[col] = coerced\n",
    "\n",
    "# Auto-convert object columns that are mostly numeric (safety)\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    if col.lower() in ('gender','partner','dependents','phoneservice','churn','customerid','contract','paymentmethod','internetservice'):\n",
    "        continue\n",
    "    coerced, frac = robust_convert_numeric(df[col])\n",
    "    if frac > 0.85:\n",
    "        print(f\"Auto-converting {col} to numeric (frac={frac:.3f})\")\n",
    "        df[col] = coerced\n",
    "\n",
    "# --------------- 3. Basic cleaning and imputation ---------------\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop(columns=['customerID'])\n",
    "if 'Churn' not in df.columns:\n",
    "    raise ValueError(\"Missing Churn column\")\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Impute numeric NaNs with median\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'Churn' in num_cols: num_cols.remove('Churn')\n",
    "if len(num_cols) > 0:\n",
    "    df[num_cols] = SimpleImputer(strategy='median').fit_transform(df[num_cols])\n",
    "\n",
    "# Fill categorical missing\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if len(cat_cols) > 0:\n",
    "    df[cat_cols] = df[cat_cols].fillna(\"Missing\")\n",
    "\n",
    "# --------------- 4. Encoding ---------------\n",
    "df_enc = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "X = df_enc.drop(columns=['Churn'])\n",
    "y = df_enc['Churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=RANDOM_STATE)\n",
    "print(\"Train/test shapes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# --------------- 5. Model training ---------------\n",
    "use_xgb = False\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    use_xgb = True\n",
    "    print(\"XGBoost available\")\n",
    "except Exception as e:\n",
    "    print(\"XGBoost not available:\", e)\n",
    "\n",
    "if use_xgb:\n",
    "    # ensure param numeric and explicit base_score\n",
    "    scale_pos_weight = float((y_train==0).sum() / (y_train==1).sum())\n",
    "    model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='auc', random_state=RANDOM_STATE,\n",
    "                              scale_pos_weight=scale_pos_weight, base_score=0.5, n_jobs=-1)\n",
    "else:\n",
    "    model = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# If XGBoost, set booster param to numeric string explicitly to avoid SHAP reading weird strings\n",
    "if use_xgb:\n",
    "    try:\n",
    "        booster = model.get_booster()\n",
    "        # set base_score to a numeric string that SHAP can parse\n",
    "        booster.set_param({'base_score': '0.5'})\n",
    "        print(\"Set booster.base_score to numeric string '0.5' to avoid SHAP parsing issues\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not set booster params:\", e)\n",
    "\n",
    "# --------------- 6. Evaluation ---------------\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_proba >= 0.5).astype(int)\n",
    "auc = roc_auc_score(y_test, y_proba)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "print(f\"Metrics -> AUC: {auc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "# --------------- 7. Explainability: SHAP with robust fallbacks ---------------\n",
    "shap_available = False\n",
    "try:\n",
    "    import shap\n",
    "    shap_available = True\n",
    "    print(\"SHAP version:\", shap.__version__)\n",
    "except Exception as e:\n",
    "    print(\"SHAP not installed:\", e)\n",
    "    shap_available = False\n",
    "\n",
    "shap_values_pos = None\n",
    "global_imp = None\n",
    "\n",
    "if shap_available:\n",
    "    # Convert data to numeric numpy arrays to avoid object dtype issues in SHAP\n",
    "    X_train_np = X_train.values.astype(np.float32)\n",
    "    X_test_np = X_test.values.astype(np.float32)\n",
    "\n",
    "    # Try TreeExplainer first (fast for trees). If it throws, fall back to shap.Explainer on predict_proba.\n",
    "    try:\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        try:\n",
    "            sv = explainer.shap_values(X_test_np)  # older API\n",
    "        except Exception:\n",
    "            sv = explainer(X_test_np)  # newer API\n",
    "        if isinstance(sv, list):\n",
    "            shap_values_pos = sv[1]\n",
    "        else:\n",
    "            try:\n",
    "                shap_values_pos = np.array(sv.values)\n",
    "            except Exception:\n",
    "                shap_values_pos = np.array(sv)\n",
    "        print(\"TreeExplainer succeeded\")\n",
    "    except Exception as e_tree:\n",
    "        print(\"TreeExplainer failed:\", type(e_tree).__name__, str(e_tree))\n",
    "        print(\"Trying shap.Explainer with model.predict_proba and numpy arrays (slower)\")\n",
    "        try:\n",
    "            predict_proba = lambda x: model.predict_proba(x)[:, 1]\n",
    "            explainer2 = shap.Explainer(predict_proba, X_train_np)  # pass numpy\n",
    "            sv2 = explainer2(X_test_np)\n",
    "            # new shap.Explanation likely returns sv2.values with shape (n_samples, n_features)\n",
    "            try:\n",
    "                shap_values_pos = np.array(sv2.values)\n",
    "            except Exception:\n",
    "                shap_values_pos = np.array(sv2)\n",
    "            print(\"shap.Explainer succeeded\")\n",
    "        except Exception as e_expl:\n",
    "            print(\"shap.Explainer also failed:\", type(e_expl).__name__, str(e_expl))\n",
    "            shap_values_pos = None\n",
    "\n",
    "    # If we have shap_values_pos, process and save plots\n",
    "    if shap_values_pos is not None:\n",
    "        shap_values_pos = np.asarray(shap_values_pos)\n",
    "        # handle possible extra dims\n",
    "        if shap_values_pos.ndim == 3:\n",
    "            # try to reduce to (n_samples, n_features)\n",
    "            shap_values_pos = shap_values_pos.reshape(shap_values_pos.shape[1], shap_values_pos.shape[2])\n",
    "\n",
    "        mean_abs_shap = np.abs(shap_values_pos).mean(axis=0)\n",
    "        global_imp = pd.Series(mean_abs_shap, index=X_test.columns).sort_values(ascending=False)\n",
    "        print(\"Top 10 features by mean |SHAP|:\")\n",
    "        print(global_imp.head(10))\n",
    "\n",
    "        # Save global mean|SHAP| bar\n",
    "        plt.figure(figsize=(12,6))\n",
    "        global_imp.head(20).plot.bar()\n",
    "        plt.title(\"Global feature importance (mean |SHAP|) - top 20\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUTPUT_FOLDER, \"global_shap_importance.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # SHAP summary (beeswarm)\n",
    "        try:\n",
    "            plt.figure()\n",
    "            shap.summary_plot(shap_values_pos, X_test_np, show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUTPUT_FOLDER, \"shap_summary_beeswarm.png\"), bbox_inches='tight')\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(\"Could not create SHAP beeswarm:\", e)\n",
    "\n",
    "        # Dependence plots for top-3 features\n",
    "        top3 = global_imp.head(3).index.tolist()\n",
    "        for feat in top3:\n",
    "            try:\n",
    "                plt.figure(figsize=(6,4))\n",
    "                # shap.dependence_plot accepts DataFrame too; pass X_test (columns preserved) to label axes\n",
    "                shap.dependence_plot(feat, shap_values_pos, X_test, show=False)\n",
    "                plt.tight_layout()\n",
    "                safe = feat.replace(' ', '_').replace('/', '_')\n",
    "                plt.savefig(os.path.join(OUTPUT_FOLDER, f\"shap_dependence_{safe}.png\"))\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Dependence plot failed for {feat}:\", e)\n",
    "\n",
    "        # Local explanations: pick three representatives\n",
    "        preds = (y_proba >= 0.5).astype(int)\n",
    "        churn_idx = np.where((preds==1) & (y_test.values==1))[0]\n",
    "        nonchurn_idx = np.where((preds==0) & (y_test.values==0))[0]\n",
    "        borderline_idx = np.argmin(np.abs(y_proba - 0.5))\n",
    "        selected = {\n",
    "            \"predicted_churn\": int(X_test.index[churn_idx[0]]) if len(churn_idx)>0 else None,\n",
    "            \"predicted_nonchurn\": int(X_test.index[nonchurn_idx[0]]) if len(nonchurn_idx)>0 else None,\n",
    "            \"borderline\": int(X_test.index[borderline_idx])\n",
    "        }\n",
    "        print(\"Selected indices for local SHAP:\", selected)\n",
    "\n",
    "        for name, idx in selected.items():\n",
    "            if idx is None:\n",
    "                continue\n",
    "            pos = list(X_test.index).index(idx)\n",
    "            try:\n",
    "                base_val = explainer.expected_value if 'explainer' in locals() and hasattr(explainer, \"expected_value\") else None\n",
    "                ev = shap.Explanation(values=shap_values_pos[pos], base_values=base_val, data=X_test.iloc[pos])\n",
    "                plt.figure(figsize=(10,4))\n",
    "                shap.plots.waterfall(ev, show=False)\n",
    "                plt.title(f\"Local SHAP waterfall - {name} (idx {idx})\")\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(OUTPUT_FOLDER, f\"shap_local_waterfall_{name}_{idx}.png\"))\n",
    "                plt.close()\n",
    "            except Exception as e_local:\n",
    "                # fallback: save top local SHAP values as CSV\n",
    "                local_sh = pd.Series(shap_values_pos[pos], index=X_test.columns)\n",
    "                local_sh.abs().sort_values(ascending=False).head(40).to_csv(\n",
    "                    os.path.join(OUTPUT_FOLDER, f\"shap_local_top_{name}_{idx}.csv\")\n",
    "                )\n",
    "        print(\"SHAP artifacts saved to:\", OUTPUT_FOLDER)\n",
    "    else:\n",
    "        print(\"SHAP computation did not produce values. Will use permutation importance fallback.\")\n",
    "        shap_available = False\n",
    "\n",
    "# --------------- 8. Fallback (permutation importance + PDP) ---------------\n",
    "if not shap_available or (shap_values_pos is None):\n",
    "    print(\"Running permutation importance fallback.\")\n",
    "    r = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=RANDOM_STATE, n_jobs=1)\n",
    "    perm_imp = pd.Series(r.importances_mean, index=X_test.columns).sort_values(ascending=False)\n",
    "    perm_imp.head(20).to_csv(os.path.join(OUTPUT_FOLDER, \"permutation_importance_top20.csv\"))\n",
    "    plt.figure(figsize=(12,6))\n",
    "    perm_imp.head(20).plot.bar()\n",
    "    plt.title(\"Permutation importance - top 20\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_FOLDER, \"permutation_importance_top20.png\"))\n",
    "    plt.close()\n",
    "    top3 = perm_imp.head(3).index.tolist()\n",
    "    for feat in top3:\n",
    "        try:\n",
    "            fig, ax = plt.subplots(figsize=(6,4))\n",
    "            PartialDependenceDisplay.from_estimator(model, X_test, [feat], ax=ax)\n",
    "            plt.title(f\"PDP - {feat}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUTPUT_FOLDER, f\"pdp_{feat.replace(' ', '_').replace('/', '_')}.png\"))\n",
    "            plt.close()\n",
    "        except Exception as e:\n",
    "            print(\"PDP failed for\", feat, \":\", e)\n",
    "    # Local approximate contributions using feature importances\n",
    "    fi = None\n",
    "    try:\n",
    "        fi = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "    except Exception:\n",
    "        pass\n",
    "    preds = (y_proba >= 0.5).astype(int)\n",
    "    churn_idx = np.where((preds==1) & (y_test.values==1))[0]\n",
    "    nonchurn_idx = np.where((preds==0) & (y_test.values==0))[0]\n",
    "    borderline_idx = np.argmin(np.abs(y_proba - 0.5))\n",
    "    test_indices = X_test.index.to_numpy()\n",
    "    selected = {\n",
    "        \"predicted_churn\": int(test_indices[churn_idx[0]]) if len(churn_idx)>0 else None,\n",
    "        \"predicted_nonchurn\": int(test_indices[nonchurn_idx[0]]) if len(nonchurn_idx)>0 else None,\n",
    "        \"borderline\": int(test_indices[borderline_idx])\n",
    "    }\n",
    "    for name, idx in selected.items():\n",
    "        if idx is None: continue\n",
    "        pos = list(X_test.index).index(idx)\n",
    "        row = X_test.iloc[pos]\n",
    "        if fi is not None:\n",
    "            contrib = (row - X_train.mean()) * fi\n",
    "            contrib = contrib.sort_values(key=lambda x: np.abs(x), ascending=False).head(30)\n",
    "            contrib.to_csv(os.path.join(OUTPUT_FOLDER, f\"fallback_local_contrib_{name}_{idx}.csv\"))\n",
    "    print(\"Fallback artifacts saved to:\", OUTPUT_FOLDER)\n",
    "\n",
    "# --------------- 9. Summary file ---------------\n",
    "with open(os.path.join(OUTPUT_FOLDER, \"run_summary.txt\"), \"w\") as f:\n",
    "    f.write(\"Model evaluation:\\n\")\n",
    "    f.write(f\"AUC: {auc:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1: {f1:.4f}\\n\\n\")\n",
    "    if shap_values_pos is not None:\n",
    "        f.write(\"SHAP global and local outputs saved.\\n\")\n",
    "    else:\n",
    "        f.write(\"SHAP failed in this environment; permutation importance + PDP fallbacks saved.\\n\")\n",
    "    f.write(f\"Outputs folder: {OUTPUT_FOLDER}\\n\")\n",
    "\n",
    "print(\"Done. Outputs in:\", OUTPUT_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d32fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
